{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "import keras\n",
    "\n",
    "from config import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning\n",
    "dataset = config.DATASET\n",
    "n_points = config.N_POINTS\n",
    "cell = config.CELL\n",
    "num_classes = config.NUM_CLASSES\n",
    "extension = config.EXTENSION\n",
    "class_name = config.CLASS_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_or_test = [\"train\",\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#読み込み，書き込み用ディレクトリ\n",
    "data_dir = config.DATA_DIR\n",
    "vox_dir = config.VOX_DIR\n",
    "fig_dir =  config.FIG_DIR\n",
    "dist_dir = config.DIST_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = [data_dir , vox_dir , fig_dir , dist_dir]\n",
    "for directory in dir_list:\n",
    "    if os.path.exists(directory) == False:\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainとTestのデータdirectory作成\n",
    "for t in train_or_test:\n",
    "    for cl in class_name:\n",
    "        if os.path.exists(data_dir + cl + \"/\" + t + \"/\") == False:\n",
    "            os.makedirs(data_dir + cl + \"/\" + t + \"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_off(filename):\n",
    "    # read OFF file\n",
    "    with open(filename,\"r\") as handle:\n",
    "        off = handle.read().rstrip().split(\"\\n\")\n",
    "        \n",
    "    #OFFファイルが不正かどうか判定\n",
    "    if off[0] != \"OFF\":\n",
    "#         print(\"{} is broken!!\".format(filename))\n",
    "        params = list(off[0].split(\" \"))\n",
    "        n_vertices = int(params[0].strip(\"OFF\"))\n",
    "        n_faces = int(params[1])\n",
    "        off.insert(0, \"OFF\")\n",
    "    \n",
    "    else:\n",
    "        #get params and faces\n",
    "        params = list(map(int, off[1].split(\" \")))\n",
    "        n_vertices = params[0]\n",
    "        n_faces = params[1]\n",
    "\n",
    "    # read  Vertex coordinates\n",
    "    vertices = []\n",
    "    for n in range(n_vertices):\n",
    "        coords = list(map(float, off[2+n].split()))\n",
    "        vertices.append(coords)\n",
    "\n",
    "    # read information of faces\n",
    "    faces = []\n",
    "    for n in range(n_faces):\n",
    "        connects = list(map(int, off[2 + n_vertices + n].split(\" \")[1:4]))\n",
    "        faces.append(connects)\n",
    "\n",
    "    return vertices, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_stl(filename):\n",
    "    # read STL file\n",
    "    with open(filename,\"r\") as handle:\n",
    "        stl = handle.read().rstrip().split(\"\\n\")\n",
    "        \n",
    "    #get vertice\n",
    "    vertice = []\n",
    "    for i in range(len(stl)):\n",
    "        pool = stl[i].split()\n",
    "        if pool[0] == \"vertex\":\n",
    "            vertex = list(map(float, pool[1:]))\n",
    "            vertice.append(vertex)\n",
    "            \n",
    "    seen = []\n",
    "    unique_vertice = [x for x in vertice if x not in seen and not seen.append(x)]\n",
    "            \n",
    "    #get faces\n",
    "    faces = []\n",
    "    for n in range(len(stl)):\n",
    "        if stl[n].split() == ['outer', 'loop']:\n",
    "            indexes = []\n",
    "            for i in range(3):\n",
    "                index = get_index_2d_list(unique_vertice, list(map(float,stl[n+i+1].split()[1:])))\n",
    "                indexes.append(index)\n",
    "            faces.append(indexes)\n",
    "\n",
    "    return unique_vertice, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def generate_points(points, face_ids, num_generated_point=1000):\n",
    "    \n",
    "    points = np.array(points)\n",
    "    face_ids = np.array(face_ids)\n",
    "    \n",
    "    # compute area\n",
    "    vec1 = points[face_ids[:,0]] - points[face_ids[:,1]]\n",
    "    vec2 = points[face_ids[:,1]] - points[face_ids[:,2]]\n",
    "    cross_product = np.cross(vec1, vec2)\n",
    "    area = np.sqrt(np.power(cross_product, 2).sum(axis=1))\n",
    "\n",
    "    # cumsum area\n",
    "    cum_area = np.cumsum(area)\n",
    "\n",
    "    # generate random \n",
    "    random = np.random.rand(num_generated_point) * cum_area[-1]\n",
    "\n",
    "    # convert random to index\n",
    "    #random_idx = [bisect.bisect_left(cum_area, x) for x in random]\n",
    "    random_idx = np.random.choice(np.arange(len(face_ids)), size=num_generated_point, p=area/cum_area[-1])\n",
    "\n",
    "    #import pdb; pdb.set_trace()\n",
    "\n",
    "    # generate points\n",
    "    r1 = np.tile(np.random.rand(num_generated_point), (3, 1)).T\n",
    "    r2 = np.tile(np.random.rand(num_generated_point), (3, 1)).T\n",
    "\n",
    "    generated_points = (1 - np.sqrt(r1))*points[face_ids[random_idx, 0]] + np.sqrt(r1)*(1-r2)*points[face_ids[random_idx, 1]] + np.sqrt(r1)*r2*points[face_ids[random_idx, 2]]\n",
    "\n",
    "    return generated_points, random_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def voxilize(np_pc,cell):\n",
    "# ボクセル化した配列を返す\n",
    "    max_dist = 0.0\n",
    "    for it in range(0,3):\n",
    "        # 最大値と最小値の距離を求める\n",
    "        min_ = np.amin(np_pc[:,it])\n",
    "        max_ = np.amax(np_pc[:,it])\n",
    "        dist = max_-min_\n",
    "\n",
    "        #xyzで一番並行距離が大きいのを求める\n",
    "        if dist > max_dist:\n",
    "            max_dist = dist\n",
    "            \n",
    "    for it in range(0,3):\n",
    "\n",
    "        # 最大値と最小値の距離を求める\n",
    "        min_ = np.amin(np_pc[:,it])\n",
    "        max_ = np.amax(np_pc[:,it])\n",
    "        dist = max_-min_\n",
    "        \n",
    "        #中心座標を 0,0,0にセットする（原点が中心にくるようにする）\n",
    "        np_pc[:,it] = np_pc[:,it] - dist/2 - min_\n",
    "\n",
    "        #covered cell\n",
    "        cls = cell - 3\n",
    "\n",
    "        #ボクセル一個当たりのサイズを求める\n",
    "        vox_sz = max_dist/(cls-1)\n",
    "\n",
    "        #上で算出した値で各点を割る。これで各点は(-14, 14)の範囲の値になる\n",
    "        np_pc[:,it] = np_pc[:,it]/vox_sz\n",
    "\n",
    "        #各点が全て正の整数になるよう移動。これで各点は[0, 30]になる（多分）\n",
    "        np_pc[:,it] = np_pc[:,it] + (cls-1)/2\n",
    "\n",
    "\n",
    "    #整数にする\n",
    "    np_pc = np.rint(np_pc).astype(np.uint32)\n",
    "\n",
    "\n",
    "    #３０＊３０＊３０の配列を作り，点が存在する場合は1、存在しない場合は0を入力する。\n",
    "    vox = np.zeros([cell-2,cell-2,cell-2])\n",
    "\n",
    "    # (pc_x, pc_y, pc_z)にnp_pcの座標を代入する\n",
    "    for (pc_x, pc_y, pc_z) in np_pc:\n",
    "\n",
    "#     # 点が存在しても20%の確率で0とし、データにノイズを加え、汎用性を上げている\n",
    "#     # ここ，ノイジーなデータの場合８０よりも小さい数字にしたほうがいいかもね？\n",
    "#         if random.randint(0,100) < 80:\n",
    "        vox[pc_x, pc_y, pc_z] = 1\n",
    "\n",
    "    np_vox = np.zeros([1,cell,cell,cell,1])\n",
    "    np_vox[0, 1:-1, 1:-1, 1:-1,0] = vox\n",
    "\n",
    "    return np_vox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def voxel_scatter(np_vox):\n",
    "# キレイに整形するやつ\n",
    "    #空の配列を作る\n",
    "    vox_scat = np.zeros([0,3], dtype= np.uint32)\n",
    "\n",
    "    #32回\n",
    "    for x in range(0,np_vox.shape[1]):\n",
    "        #32回\n",
    "        for y in range(0,np_vox.shape[2]):\n",
    "            #32回\n",
    "            for z in range(0,np_vox.shape[3]):\n",
    "                #（ｘ，ｙ，ｚ）に１が入っていればその座標を返す\n",
    "                if np_vox[0,x,y,z,0] == 1.0:\n",
    "                    arr_tmp = np.zeros([1,3],dtype=np.uint32)\n",
    "                    arr_tmp[0,:] = (x,y,z)\n",
    "                    vox_scat = np.concatenate((vox_scat,arr_tmp))\n",
    "    return vox_scat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_vox_stl(filename, n_points = n_points):\n",
    "    #shape(N,1,32,32,32)の配列を返す\n",
    "    vertices, faces = load_stl(filename)\n",
    "    points,faces = generate_points(vertices, faces, n_points)\n",
    "    # ValueError: sequence too large; cannot be greater than 32の回避策\n",
    "    # list 2 numpy.ndarray\n",
    "    pc = np.empty((len(points), len(points[0])))\n",
    "    pc[:] = points\n",
    "    vox = voxilize(pc,cell)\n",
    "\n",
    "    return vox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_vox_off(filename, n_points = n_points):\n",
    "    #shape(N,1,32,32,32)の配列を返す\n",
    "    vertices, faces = load_off(filename)\n",
    "    points,faces = generate_points(vertices, faces, n_points)\n",
    "    # ValueError: sequence too large; cannot be greater than 32の回避策\n",
    "    # list 2 numpy.ndarray\n",
    "    pc = np.empty((len(points), len(points[0])))\n",
    "    pc[:] = points\n",
    "    vox = voxilize(pc,cell)\n",
    "\n",
    "    return vox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# XYZ 長さの取得\n",
    "def calc_dist_off(filename):\n",
    "    vertices, faces = load_off(filename)\n",
    "    point =  np.array(vertices)\n",
    "    dist = np.zeros(3)\n",
    "    for i in range(0,3):\n",
    "        min_ = np.amin(point[:,i])\n",
    "        max_ = np.amax(point[:,i])\n",
    "        dist_ = max_ - min_\n",
    "        if dist_ < 0.001:\n",
    "            dist_ = 0.001\n",
    "        dist[i] = dist_\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XYZ 長さの取得\n",
    "def calc_dist_stl(filename):\n",
    "    vertices, faces = load_stl(filename)\n",
    "    point =  np.array(vertices)\n",
    "    dist = np.zeros(3)\n",
    "    for i in range(0,3):\n",
    "        min_ = np.amin(point[:,i])\n",
    "        max_ = np.amax(point[:,i])\n",
    "        dist_ = max_ - min_\n",
    "        if dist_ < 0.001:\n",
    "            dist_ = 0.001\n",
    "        dist[i] = dist_\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ディレクトリ操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if dataset == \"3D_SAMPLE\":\n",
    "    # train_or_testの分ける\n",
    "    for cl in class_name:\n",
    "        namelist = glob.glob(data_dir+ cl +\"/*\")\n",
    "        namelist.remove(data_dir+ cl + \"/train\")\n",
    "        namelist.remove(data_dir+ cl + \"/test\")\n",
    "        for i in range(len(namelist)):\n",
    "            if i%5 == 0 :\n",
    "                shutil.move(namelist[i], data_dir + cl + \"/test/.\")\n",
    "    #             print(namelist[i])\n",
    "            else:\n",
    "                shutil.move(namelist[i], data_dir + cl + \"/train/.\")\n",
    "    #             print(namelist[i])\n",
    "#  nameの取得\n",
    "namelist_all = []\n",
    "\n",
    "for cl in class_name:\n",
    "    \n",
    "    for t in train_or_test:\n",
    "        i = 0\n",
    "        #ファイル名を取得\n",
    "        namelist_class = glob.glob(data_dir+ cl +\"/\" + t + \"/*\")\n",
    "        namelist_class.sort()\n",
    "        namelist_all.append(namelist_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ボクセルのnumpy保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airplane\n",
      "bookshelf\n",
      "chair\n",
      "desk\n",
      "glass_box\n",
      "laptop\n",
      "person\n",
      "range_hood\n",
      "stool\n",
      "tv_stand\n",
      "bathtub\n",
      "bottle\n",
      "cone\n",
      "door\n",
      "guitar\n",
      "mantel\n",
      "piano\n",
      "sink\n",
      "table\n",
      "vase\n",
      "bed\n",
      "bowl\n",
      "cup\n",
      "dresser\n",
      "keyboard\n",
      "monitor\n",
      "plant\n",
      "sofa\n",
      "tent\n",
      "wardrobe\n",
      "bench\n",
      "car\n",
      "curtain\n",
      "flower_pot\n",
      "lamp\n",
      "night_stand\n",
      "radio\n",
      "stairs\n",
      "toilet\n",
      "xbox\n",
      "airplane\n",
      "bookshelf\n",
      "chair\n",
      "desk\n",
      "glass_box\n",
      "laptop\n",
      "person\n",
      "range_hood\n",
      "stool\n",
      "tv_stand\n",
      "bathtub\n",
      "bottle\n",
      "cone\n",
      "door\n",
      "guitar\n",
      "mantel\n",
      "piano\n",
      "sink\n",
      "table\n",
      "vase\n",
      "bed\n",
      "bowl\n",
      "cup\n",
      "dresser\n",
      "keyboard\n",
      "monitor\n",
      "plant\n",
      "sofa\n",
      "tent\n",
      "wardrobe\n",
      "bench\n",
      "car\n",
      "curtain\n",
      "flower_pot\n",
      "lamp\n",
      "night_stand\n",
      "radio\n",
      "stairs\n",
      "toilet\n",
      "xbox\n"
     ]
    }
   ],
   "source": [
    "off_voxilize = False\n",
    "\n",
    "for t in train_or_test:\n",
    "    for cl in  class_name:\n",
    "        print(cl)\n",
    "        \n",
    "        #すでにボクセル化が済んていればスキップ\n",
    "        if os.path.exists(vox_dir + \"x_train.npy\") == True:\n",
    "#             print(\"{} is exist.\".format(vox_dir + cl + t + \".npy\"))\n",
    "            off_voxilize = True\n",
    "            continue\n",
    "        \n",
    "        #すでに存在してるnpyファイルはスキップ\n",
    "        if os.path.exists(vox_dir + cl + t + \".npy\") == True:\n",
    "            print(\"{} is exist.\".format(data_dir + cl + t + \".npy\"))\n",
    "            continue\n",
    "        \n",
    "        data_3d = glob.glob(data_dir+ cl +\"/\" + t + \"/*\")\n",
    "        data_3d.sort()\n",
    "        flag0 = True\n",
    "        \n",
    "        for d in data_3d:\n",
    "            if flag0 :\n",
    "                #stl,off判定\n",
    "                if extension == \".off\":\n",
    "                    vox_data = load_vox_off(d)\n",
    "                elif extension == \".stl\":\n",
    "                    vox_data = load_vox_stl(d)\n",
    "                flag0 = False\n",
    "                continue\n",
    "            if extension == \".off\":\n",
    "                vox_data_ = load_vox_off(d)\n",
    "            elif extension == \".stl\":\n",
    "                vox_data_ = load_vox_stl(d)    \n",
    "            \n",
    "            vox_data = np.append(vox_data, vox_data_, axis=0)\n",
    "        np.save(vox_dir + cl + t + \".npy\", vox_data)\n",
    "#クラス毎，TestTrain毎ボクセル化されたnpzが生成される（N,32,32,32,1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.off'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'np_vox/ModelNet40/cell32/airplanetrain.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-c81d5795a785>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswich_npy\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0mnpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvox_dir\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mcl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0mnum_of_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mswich_npy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'np_vox/ModelNet40/cell32/airplanetrain.npy'"
     ]
    }
   ],
   "source": [
    "\n",
    "#ココらへん可読性わるすぎ\n",
    "if not off_voxilize:\n",
    "    # データ整形\n",
    "    for t in train_or_test:\n",
    "        swich_npy = True \n",
    "        num_of_data = []#init\n",
    "        for cl in class_name:\n",
    "            if swich_npy == True:\n",
    "                npy = np.load(vox_dir  + cl + t + \".npy\")\n",
    "                num_of_data.append(npy.shape[0])\n",
    "                swich_npy = False\n",
    "            else:\n",
    "                npy_ = np.load(vox_dir  + cl + t + \".npy\")\n",
    "                npy = np.append(npy,npy_,axis=0)\n",
    "                num_of_data.append(npy_.shape[0])\n",
    "        if t == \"train\":\n",
    "            x_train = npy\n",
    "            y_train = num_of_data\n",
    "        if t == \"test\":\n",
    "            x_test = npy\n",
    "            y_test = num_of_data\n",
    "            \n",
    "        \n",
    "    # ラベルの生成\n",
    "    for t in train_or_test:\n",
    "        if t == \"train\":\n",
    "            for i in range(num_classes):\n",
    "                if i == 0:\n",
    "                    label = np.full(y_train[i] , i )    \n",
    "                else:\n",
    "                    label_ = np.full(y_train[i] , i )   \n",
    "                    label = np.append(label, label_, axis=0)\n",
    "            y_train = label\n",
    "\n",
    "        if t == \"test\":\n",
    "            for i in range(num_classes):\n",
    "                if i == 0:\n",
    "                    label = np.full(y_test[i] , i )    \n",
    "                else:\n",
    "                    label_ = np.full(y_test[i] , i )   \n",
    "                    label = np.append(label, label_, axis=0)\n",
    "            y_test = label\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    # 保存\n",
    "    npy = [\"x_train.npy\" , \"x_test.npy\" , \"y_train.npy\" , \"y_test.npy\"]\n",
    "    data = [x_train , x_test , y_train , y_test]\n",
    "    for i in range(len(npy)):\n",
    "        np.save(vox_dir + npy[i],data[i])\n",
    "        \n",
    "    # 不要ファイルの除去\n",
    "    for i in os.listdir(vox_dir):\n",
    "        if not i in npy:\n",
    "            os.remove(vox_dir + i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 距離の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_calcrated = False\n",
    "\n",
    "for t in train_or_test:\n",
    "    for cl in  class_name:\n",
    "        print(cl)\n",
    "        \n",
    "        #すでに距離の計算が済んていればスキップ\n",
    "        if os.path.exists(dist_dir + \"x_train.npy\") == True:\n",
    "#             print(\"{} is exist.\".format(vox_dir + cl + t + \".npy\"))\n",
    "            dist_calcrated = True\n",
    "            continue\n",
    "        \n",
    "        #すでに存在してるnpyファイルはスキップ\n",
    "        if os.path.exists(dist_dir + cl + t + \".npy\") == True:\n",
    "#             print(\"{} is exist.\".format(data_dir + cl + t + \".npy\"))\n",
    "            continue\n",
    "        \n",
    "        data_3d = glob.glob(data_dir+ cl +\"/\" + t + \"/*\")\n",
    "        data_3d.sort()\n",
    "        flag0 = True\n",
    "        for d in data_3d:\n",
    "            if flag0:\n",
    "                if extension == \".off\":\n",
    "                    dist = calc_dist_off(d)\n",
    "                elif extension == \".stl\":\n",
    "                    dist = calc_dist_stl(d)\n",
    "                dist = [dist]\n",
    "                flag0 = False\n",
    "                continue\n",
    "            if extension == \".off\":\n",
    "                dist_ =  calc_dist_off(d)\n",
    "            elif extension == \".stl\":\n",
    "                dist_ = calc_dist_stl(d)\n",
    "            \n",
    "            dist = np.append(dist, [dist_], axis=0)\n",
    "#             print(dist.shape)\n",
    "        np.save(dist_dir + cl + t + \".npy\", dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dist_calcrated' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d43e8680812a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdist_calcrated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# データ整形\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_or_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mswich_npy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mnum_of_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dist_calcrated' is not defined"
     ]
    }
   ],
   "source": [
    "if not dist_calcrated:\n",
    "    # データ整形\n",
    "    for t in train_or_test:\n",
    "        swich_npy = True \n",
    "        num_of_data = []#init\n",
    "        for cl in class_name:\n",
    "            if swich_npy == True:\n",
    "                npy = np.load(dist_dir  + cl + t + \".npy\")\n",
    "                num_of_data.append(npy.shape[0])\n",
    "                swich_npy = False\n",
    "            else:\n",
    "                npy_ = np.load(dist_dir  + cl + t + \".npy\")\n",
    "                npy = np.append(npy,npy_,axis=0)\n",
    "                num_of_data.append(npy_.shape[0])\n",
    "        if t == \"train\":\n",
    "            x_train = npy\n",
    "            y_train = num_of_data\n",
    "        if t == \"test\":\n",
    "            x_test = npy\n",
    "            y_test = num_of_data\n",
    "            \n",
    "        \n",
    "    # ラベルの生成\n",
    "    for t in train_or_test:\n",
    "        if t == \"train\":\n",
    "            for i in range(num_classes):\n",
    "                if i == 0:\n",
    "                    label = np.full(y_train[i] , i )    \n",
    "                else:\n",
    "                    label_ = np.full(y_train[i] , i )   \n",
    "                    label = np.append(label, label_, axis=0)\n",
    "            y_train = label\n",
    "\n",
    "        if t == \"test\":\n",
    "            for i in range(num_classes):\n",
    "                if i == 0:\n",
    "                    label = np.full(y_test[i] , i )    \n",
    "                else:\n",
    "                    label_ = np.full(y_test[i] , i )   \n",
    "                    label = np.append(label, label_, axis=0)\n",
    "            y_test = label\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    # 保存\n",
    "    npy = [\"x_train.npy\" , \"x_test.npy\" , \"y_train.npy\" , \"y_test.npy\"]\n",
    "    data = [x_train , x_test , y_train , y_test]\n",
    "    for i in range(len(npy)):\n",
    "        np.save(dist_dir + npy[i],data[i])\n",
    "        \n",
    "    # 不要ファイルの除去\n",
    "#     for i in os.listdir(dist_dir):\n",
    "#         if not i in npy:\n",
    "#             os.remove(dist_dir + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
