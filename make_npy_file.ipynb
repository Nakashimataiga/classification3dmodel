{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import shutil\n",
    "\n",
    "from config import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning\n",
    "dataset = config.DATASET\n",
    "n_points = config.N_POINTS\n",
    "cell = config.CELL\n",
    "num_classes = config.NUM_CLASSES\n",
    "extension = config.EXTENSION\n",
    "class_name = config.CLASS_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_or_test = [\"train\",\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#読み込み，書き込み用ディレクトリ\n",
    "data_dir = config.DATA_DIR\n",
    "vox_dir = config.VOX_DIR\n",
    "fig_dir =  config.FIG_DIR\n",
    "dist_dir = config.DIST_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = [data_dir , vox_dir , fig_dir , dist_dir]\n",
    "for directory in dir_list:\n",
    "    if os.path.exists(directory) == False:\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainとTestのデータdirectory作成\n",
    "for t in train_or_test:\n",
    "    for cl in class_name:\n",
    "        if os.path.exists(data_dir + cl + \"/\" + t + \"/\") == False:\n",
    "            os.makedirs(data_dir + cl + \"/\" + t + \"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_off(filename):\n",
    "    # read OFF file\n",
    "    with open(filename,\"r\") as handle:\n",
    "        off = handle.read().rstrip().split(\"\\n\")\n",
    "        \n",
    "    #OFFファイルが不正かどうか判定\n",
    "    if off[0] != \"OFF\":\n",
    "#         print(\"{} is broken!!\".format(filename))\n",
    "        params = list(off[0].split(\" \"))\n",
    "        n_vertices = int(params[0].strip(\"OFF\"))\n",
    "        n_faces = int(params[1])\n",
    "        off.insert(0, \"OFF\")\n",
    "    \n",
    "    else:\n",
    "        #get params and faces\n",
    "        params = list(map(int, off[1].split(\" \")))\n",
    "        n_vertices = params[0]\n",
    "        n_faces = params[1]\n",
    "\n",
    "    # read  Vertex coordinates\n",
    "    vertices = []\n",
    "    for n in range(n_vertices):\n",
    "        coords = list(map(float, off[2+n].split()))\n",
    "        vertices.append(coords)\n",
    "\n",
    "    # read information of faces\n",
    "    faces = []\n",
    "    for n in range(n_faces):\n",
    "        connects = list(map(int, off[2 + n_vertices + n].split(\" \")[1:4]))\n",
    "        faces.append(connects)\n",
    "\n",
    "    return vertices, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_unique_list(seq):\n",
    "    seen = []\n",
    "    return [x for x in seq if x not in seen and not seen.append(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_index_2d_list(retrieval_object,array):\n",
    "    return [i for i, x in enumerate(retrieval_object) if x == array][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_stl(filename):\n",
    "    # read STL file\n",
    "    with open(filename,\"r\") as handle:\n",
    "        stl = handle.read().rstrip().split(\"\\n\")\n",
    "        \n",
    "    #get vertice\n",
    "    vertice = []\n",
    "    for i in range(len(stl)):\n",
    "        pool = stl[i].split()\n",
    "        if pool[0] == \"vertex\":\n",
    "            vertex = list(map(float, pool[1:]))\n",
    "            vertice.append(vertex)\n",
    "            \n",
    "    unique_vertice = get_unique_list(vertice)\n",
    "            \n",
    "    #get faces\n",
    "    faces = []\n",
    "    for n in range(len(stl)):\n",
    "        if stl[n].split() == ['outer', 'loop']:\n",
    "            indexes = []\n",
    "            for i in range(3):\n",
    "                index = get_index_2d_list(unique_vertice, list(map(float,stl[n+i+1].split()[1:])))\n",
    "                indexes.append(index)\n",
    "            faces.append(indexes)\n",
    "\n",
    "    return unique_vertice, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def calc_vector_norm(a):\n",
    "#     何も分からん\n",
    "    norm = 0.0\n",
    "    for el in a:\n",
    "        norm += el *el\n",
    "    return math.sqrt(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def calc_cross_product_3d(a,b):\n",
    "#     なんもわからん\n",
    "    return [a[1]*b[2]-a[2]*b[1], a[2]*b[0]-a[0]*b[2],a[0]*b[1]-a[1]*b[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def calc_triangle_area(a, b, c):\n",
    "#     なんもわからん\n",
    "    ca = [c[0]-a[0], c[1]-a[1], c[2]-a[2]]\n",
    "    ba = [b[0]-a[0], b[1]-a[1], b[2]-a[2]]\n",
    "    cross = calc_cross_product_3d(ca, ba)\n",
    "    return 0.5 * calc_vector_norm(cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def calc_cumulative_areas(vertices, faces):\n",
    "#     なんもわからん\n",
    "    cuma = 0.0\n",
    "    cum_areas = []\n",
    "    for fc in faces:\n",
    "        cuma += calc_triangle_area(\n",
    "            vertices[fc[0]], vertices[fc[1]], vertices[fc[2]])\n",
    "        cum_areas.append(cuma)\n",
    "    return cum_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def random_select_face_id(cum_areas):\n",
    "#     なんもわからん\n",
    "    rand_area = cum_areas[-1] * random.random()\n",
    "    select_id = 0\n",
    "    for n in range(len(cum_areas)):\n",
    "        if rand_area <= cum_areas[n]:\n",
    "            select_id = n\n",
    "            break\n",
    "    return select_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def gen_random_points(vertices, faces, n_points):\n",
    "#     なんもわからん\n",
    "    cum_areas = calc_cumulative_areas(vertices, faces)\n",
    "    points = []\n",
    "    for n in range(n_points):\n",
    "        fid = random_select_face_id(cum_areas)\n",
    "        r1 = math.sqrt(random.random())\n",
    "        r2 = random.random()\n",
    "        a = vertices[faces[fid][0]]\n",
    "        b = vertices[faces[fid][1]]\n",
    "        c = vertices[faces[fid][2]]\n",
    "        xp = (1 - r1) * a[0] + r1 * (1 - r2) * b[0] + r1 * r2 * c[0]\n",
    "        yp = (1 - r1) * a[1] + r1 * (1 - r2) * b[1] + r1 * r2 * c[1]\n",
    "        zp = (1 - r1) * a[2] + r1 * (1 - r2) * b[2] + r1 * r2 * c[2]\n",
    "        points.append([xp, yp, zp])\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def voxilize(np_pc,cell):\n",
    "# ボクセル化した配列を返す\n",
    "    max_dist = 0.0\n",
    "    for it in range(0,3):\n",
    "        # 最大値と最小値の距離を求める\n",
    "        min_ = np.amin(np_pc[:,it])\n",
    "        max_ = np.amax(np_pc[:,it])\n",
    "        dist = max_-min_\n",
    "\n",
    "        #xyzで一番並行距離が大きいのを求める\n",
    "        if dist > max_dist:\n",
    "            max_dist = dist\n",
    "            \n",
    "    for it in range(0,3):\n",
    "\n",
    "        # 最大値と最小値の距離を求める\n",
    "        min_ = np.amin(np_pc[:,it])\n",
    "        max_ = np.amax(np_pc[:,it])\n",
    "        dist = max_-min_\n",
    "        \n",
    "        #中心座標を 0,0,0にセットする（原点が中心にくるようにする）\n",
    "        np_pc[:,it] = np_pc[:,it] - dist/2 - min_\n",
    "\n",
    "        #covered cell\n",
    "        cls = cell - 3\n",
    "\n",
    "        #ボクセル一個当たりのサイズを求める\n",
    "        vox_sz = max_dist/(cls-1)\n",
    "\n",
    "        #上で算出した値で各点を割る。これで各点は(-14, 14)の範囲の値になる\n",
    "        np_pc[:,it] = np_pc[:,it]/vox_sz\n",
    "\n",
    "        #各点が全て正の整数になるよう移動。これで各点は[0, 30]になる（多分）\n",
    "        np_pc[:,it] = np_pc[:,it] + (cls-1)/2\n",
    "\n",
    "\n",
    "    #整数にする\n",
    "    np_pc = np.rint(np_pc).astype(np.uint32)\n",
    "\n",
    "\n",
    "    #３０＊３０＊３０の配列を作り，点が存在する場合は1、存在しない場合は0を入力する。\n",
    "    vox = np.zeros([cell-2,cell-2,cell-2])\n",
    "\n",
    "    # (pc_x, pc_y, pc_z)にnp_pcの座標を代入する\n",
    "    for (pc_x, pc_y, pc_z) in np_pc:\n",
    "\n",
    "#     # 点が存在しても20%の確率で0とし、データにノイズを加え、汎用性を上げている\n",
    "#     # ここ，ノイジーなデータの場合８０よりも小さい数字にしたほうがいいかもね？\n",
    "#         if random.randint(0,100) < 80:\n",
    "        vox[pc_x, pc_y, pc_z] = 1\n",
    "\n",
    "    np_vox = np.zeros([1,cell,cell,cell,1])\n",
    "    np_vox[0, 1:-1, 1:-1, 1:-1,0] = vox\n",
    "\n",
    "    return np_vox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def voxel_scatter(np_vox):\n",
    "# キレイに整形するやつ\n",
    "    #空の配列を作る\n",
    "    vox_scat = np.zeros([0,3], dtype= np.uint32)\n",
    "\n",
    "    #32回\n",
    "    for x in range(0,np_vox.shape[1]):\n",
    "        #32回\n",
    "        for y in range(0,np_vox.shape[2]):\n",
    "            #32回\n",
    "            for z in range(0,np_vox.shape[3]):\n",
    "                #（ｘ，ｙ，ｚ）に１が入っていればその座標を返す\n",
    "                if np_vox[0,x,y,z,0] == 1.0:\n",
    "                    arr_tmp = np.zeros([1,3],dtype=np.uint32)\n",
    "                    arr_tmp[0,:] = (x,y,z)\n",
    "                    vox_scat = np.concatenate((vox_scat,arr_tmp))\n",
    "    return vox_scat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_vox_stl(filename):\n",
    "    #shape(N,1,32,32,32)の配列を返す\n",
    "    vertices, faces = load_stl(filename)\n",
    "    points = gen_random_points(vertices, faces, n_points)\n",
    "    # ValueError: sequence too large; cannot be greater than 32の回避策\n",
    "    # list 2 numpy.ndarray\n",
    "    pc = np.empty((len(points), len(points[0])))\n",
    "    pc[:] = points\n",
    "    vox = voxilize(pc,cell)\n",
    "\n",
    "    return vox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_vox_off(filename):\n",
    "    #shape(N,1,32,32,32)の配列を返す\n",
    "    vertices, faces = load_off(filename)\n",
    "    points = gen_random_points(vertices, faces, n_points)\n",
    "    # ValueError: sequence too large; cannot be greater than 32の回避策\n",
    "    # list 2 numpy.ndarray\n",
    "    pc = np.empty((len(points), len(points[0])))\n",
    "    pc[:] = points\n",
    "    vox = voxilize(pc,cell)\n",
    "\n",
    "    return vox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# XYZ 長さの取得\n",
    "def calc_dist(filename):\n",
    "    vertices, faces = load_stl(filename)\n",
    "    point =  np.array(vertices)\n",
    "    dist = np.zeros(3)\n",
    "    for i in range(0,3):\n",
    "        min_ = np.amin(point[:,i])\n",
    "        max_ = np.amax(point[:,i])\n",
    "        dist_ = max_ - min_\n",
    "        if dist_ < 0.001:\n",
    "            dist_ = 0.001\n",
    "        dist[i] = dist_\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ディレクトリ操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renameing auto_valve1 files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing auto_valve2 files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing auto_valve3 files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing bearing files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing bevel_gear files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing block files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing bracket1 files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing bracket2 files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing bushing files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing cylinder files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing etc files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing frame files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing gear files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing handle_valve1 files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing handle_valve2 files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing handle_valve3 files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing hinge1 files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing hinge2 files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing nut files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing pipe files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing plate files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing pully1 files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing pully2 files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing robot1 files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing robot2 files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing robot3 files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing robot4 files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing rod files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing shaft1 files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing shaft2 files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing spring files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing trigeminal_valve files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing valve_connector files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Renameing washer files ...\n",
      "train is already renamed!!\n",
      "test is already renamed!!\n",
      "Rename all!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if dataset == \"3D_SAMPLE\":\n",
    "    # train_or_testの分ける\n",
    "    for cl in class_name:\n",
    "        namelist = glob.glob(data_dir+ cl +\"/*\")\n",
    "        namelist.remove(data_dir+ cl + \"/train\")\n",
    "        namelist.remove(data_dir+ cl + \"/test\")\n",
    "        for i in range(len(namelist)):\n",
    "            if i%5 == 0 :\n",
    "                shutil.move(namelist[i], data_dir + cl + \"/test/.\")\n",
    "    #             print(namelist[i])\n",
    "            else:\n",
    "                shutil.move(namelist[i], data_dir + cl + \"/train/.\")\n",
    "    #             print(namelist[i])\n",
    "#  ====================rename===============================\n",
    "for cl in class_name:\n",
    "    print('Renameing {} files ...'.format(cl))\n",
    "    for t in train_or_test:\n",
    "        i = 0\n",
    "        #ファイル名を取得\n",
    "        namelist = glob.glob(data_dir+ cl +\"/\" + t + \"/*\")\n",
    "        if data_dir+ cl +\"/\" + t + \"/0\" + extension in namelist:\n",
    "            print(t +\" is already renamed!!\")\n",
    "            continue\n",
    "        for file in namelist:\n",
    "            os.rename(file, data_dir+ cl +'/' + t +\"/\"+ str(i) + extension)\n",
    "            i+=1\n",
    "print(\"Rename all!\")\n",
    "dir_rename_flag = True\n",
    "#  ====================rename==============================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ボクセルのnumpy保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e873ebb885a4ccd9ab90b599f26d71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=34), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_valve1\n",
      "auto_valve2\n",
      "auto_valve3\n",
      "bearing\n",
      "bevel_gear\n",
      "block\n",
      "bracket1\n",
      "bracket2\n",
      "bushing\n",
      "cylinder\n",
      "etc\n",
      "frame\n",
      "gear\n",
      "handle_valve1\n",
      "handle_valve2\n",
      "handle_valve3\n",
      "hinge1\n",
      "hinge2\n",
      "nut\n",
      "pipe\n",
      "plate\n",
      "pully1\n",
      "pully2\n",
      "robot1\n",
      "robot2\n",
      "robot3\n",
      "robot4\n",
      "rod\n",
      "shaft1\n",
      "shaft2\n",
      "spring\n",
      "trigeminal_valve\n",
      "valve_connector\n",
      "washer\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97bda809cb3145b8a7b35ab153079b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=34), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_valve1\n",
      "auto_valve2\n",
      "auto_valve3\n",
      "bearing\n",
      "bevel_gear\n",
      "block\n",
      "bracket1\n",
      "bracket2\n",
      "bushing\n",
      "cylinder\n",
      "etc\n",
      "frame\n",
      "gear\n",
      "handle_valve1\n",
      "handle_valve2\n",
      "handle_valve3\n",
      "hinge1\n",
      "hinge2\n",
      "nut\n",
      "pipe\n",
      "plate\n",
      "pully1\n",
      "pully2\n",
      "robot1\n",
      "robot2\n",
      "robot3\n",
      "robot4\n",
      "rod\n",
      "shaft1\n",
      "shaft2\n",
      "spring\n",
      "trigeminal_valve\n",
      "valve_connector\n",
      "washer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "off_voxilize = False\n",
    "\n",
    "for t in train_or_test:\n",
    "    for cl in  tqdm(class_name):\n",
    "        print(cl)\n",
    "        \n",
    "        #すでにボクセル化が済んていればスキップ\n",
    "        if os.path.exists(vox_dir + \"x_train.npy\") == True:\n",
    "#             print(\"{} is exist.\".format(vox_dir + cl + t + \".npy\"))\n",
    "            off_voxilize = True\n",
    "            continue\n",
    "        \n",
    "        #すでに存在してるnpyファイルはスキップ\n",
    "        if os.path.exists(vox_dir + cl + t + \".npy\") == True:\n",
    "            print(\"{} is exist.\".format(data_dir + cl + t + \".npy\"))\n",
    "            continue\n",
    "        \n",
    "        num = glob.glob(data_dir+ cl +\"/\" + t + \"/*\")\n",
    "        for i in tqdm(range(len(num))):\n",
    "#             print(data_dir + cl + \"/\" + t +\"/\"+ str(i) + \".stl\")\n",
    "            if i ==0  :\n",
    "                vox_data = load_vox_stl(data_dir + cl + \"/\" + t +\"/\"+ str(i) + extension)\n",
    "                continue\n",
    "            vox_data_ =  load_vox_stl(data_dir + cl + \"/\" + t +\"/\"+ str(i) + extension)\n",
    "            \n",
    "            vox_data = np.append(vox_data, vox_data_, axis=0)\n",
    "        np.save(vox_dir + cl + t + \".npy\", vox_data)\n",
    "#クラス毎，TestTrain毎ボクセル化されたnpzが生成される（N,32,32,32,1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ココらへん可読性わるすぎ\n",
    "if not off_voxilize:\n",
    "    # データ整形\n",
    "    for t in train_or_test:\n",
    "        swich_npy = True \n",
    "        num_of_data = []#init\n",
    "        for cl in class_name:\n",
    "            if swich_npy == True:\n",
    "                npy = np.load(vox_dir  + cl + t + \".npy\")\n",
    "                num_of_data.append(npy.shape[0])\n",
    "                swich_npy = False\n",
    "            else:\n",
    "                npy_ = np.load(vox_dir  + cl + t + \".npy\")\n",
    "                npy = np.append(npy,npy_,axis=0)\n",
    "                num_of_data.append(npy_.shape[0])\n",
    "        if t == \"train\":\n",
    "            x_train = npy\n",
    "            y_train = num_of_data\n",
    "        if t == \"test\":\n",
    "            x_test = npy\n",
    "            y_test = num_of_data\n",
    "            \n",
    "        \n",
    "    # ラベルの生成\n",
    "    for t in train_or_test:\n",
    "        if t == \"train\":\n",
    "            for i in range(num_classes):\n",
    "                if i == 0:\n",
    "                    label = np.full(y_train[i] , i )    \n",
    "                else:\n",
    "                    label_ = np.full(y_train[i] , i )   \n",
    "                    label = np.append(label, label_, axis=0)\n",
    "            y_train = label\n",
    "\n",
    "        if t == \"test\":\n",
    "            for i in range(num_classes):\n",
    "                if i == 0:\n",
    "                    label = np.full(y_test[i] , i )    \n",
    "                else:\n",
    "                    label_ = np.full(y_test[i] , i )   \n",
    "                    label = np.append(label, label_, axis=0)\n",
    "            y_test = label\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    # 保存\n",
    "    npy = [\"x_train.npy\" , \"x_test.npy\" , \"y_train.npy\" , \"y_test.npy\"]\n",
    "    data = [x_train , x_test , y_train , y_test]\n",
    "    for i in range(len(npy)):\n",
    "        np.save(vox_dir + npy[i],data[i])\n",
    "        \n",
    "    # 不要ファイルの除去\n",
    "    for i in os.listdir(vox_dir):\n",
    "        if not i in npy:\n",
    "            os.remove(vox_dir + i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 距離の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e83b176eb52d4799a8f78638bcc00151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=34), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_valve1\n",
      "auto_valve2\n",
      "auto_valve3\n",
      "bearing\n",
      "bevel_gear\n",
      "block\n",
      "bracket1\n",
      "bracket2\n",
      "bushing\n",
      "cylinder\n",
      "etc\n",
      "frame\n",
      "gear\n",
      "handle_valve1\n",
      "handle_valve2\n",
      "handle_valve3\n",
      "hinge1\n",
      "hinge2\n",
      "nut\n",
      "pipe\n",
      "plate\n",
      "pully1\n",
      "pully2\n",
      "robot1\n",
      "robot2\n",
      "robot3\n",
      "robot4\n",
      "rod\n",
      "shaft1\n",
      "shaft2\n",
      "spring\n",
      "trigeminal_valve\n",
      "valve_connector\n",
      "washer\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26786936719246f382a978746d501d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=34), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_valve1\n",
      "auto_valve2\n",
      "auto_valve3\n",
      "bearing\n",
      "bevel_gear\n",
      "block\n",
      "bracket1\n",
      "bracket2\n",
      "bushing\n",
      "cylinder\n",
      "etc\n",
      "frame\n",
      "gear\n",
      "handle_valve1\n",
      "handle_valve2\n",
      "handle_valve3\n",
      "hinge1\n",
      "hinge2\n",
      "nut\n",
      "pipe\n",
      "plate\n",
      "pully1\n",
      "pully2\n",
      "robot1\n",
      "robot2\n",
      "robot3\n",
      "robot4\n",
      "rod\n",
      "shaft1\n",
      "shaft2\n",
      "spring\n",
      "trigeminal_valve\n",
      "valve_connector\n",
      "washer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dist_calcrated = False\n",
    "for t in train_or_test:\n",
    "    for cl in  tqdm(class_name):\n",
    "        print(cl)\n",
    "        \n",
    "        #すでに距離の計算が済んていればスキップ\n",
    "        if os.path.exists(dist_dir + \"x_train.npy\") == True:\n",
    "#             print(\"{} is exist.\".format(vox_dir + cl + t + \".npy\"))\n",
    "            dist_calcrated = True\n",
    "            continue\n",
    "        \n",
    "        #すでに存在してるnpyファイルはスキップ\n",
    "        if os.path.exists(dist_dir + cl + t + \".npy\") == True:\n",
    "#             print(\"{} is exist.\".format(data_dir + cl + t + \".npy\"))\n",
    "            continue\n",
    "        \n",
    "        num = glob.glob(data_dir+ cl +\"/\" + t + \"/*\")\n",
    "        for i in tqdm(range(len(num))):\n",
    "            if i ==0  :\n",
    "                dist = calc_dist(data_dir + cl + \"/\" + t +\"/\"+ str(i) + extension)\n",
    "                dist = [dist]\n",
    "                continue\n",
    "            dist_ =  calc_dist(data_dir + cl + \"/\" + t +\"/\"+ str(i) + extension                                                                                                              )\n",
    "            \n",
    "            dist = np.append(dist, [dist_], axis=0)\n",
    "#             print(dist.shape)\n",
    "        np.save(dist_dir + cl + t + \".npy\", dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dist_calcrated:\n",
    "    # データ整形\n",
    "    for t in train_or_test:\n",
    "        swich_npy = True \n",
    "        num_of_data = []#init\n",
    "        for cl in class_name:\n",
    "            if swich_npy == True:\n",
    "                npy = np.load(dist_dir  + cl + t + \".npy\")\n",
    "                num_of_data.append(npy.shape[0])\n",
    "                swich_npy = False\n",
    "            else:\n",
    "                npy_ = np.load(dist_dir  + cl + t + \".npy\")\n",
    "                npy = np.append(npy,npy_,axis=0)\n",
    "                num_of_data.append(npy_.shape[0])\n",
    "        if t == \"train\":\n",
    "            x_train = npy\n",
    "            y_train = num_of_data\n",
    "        if t == \"test\":\n",
    "            x_test = npy\n",
    "            y_test = num_of_data\n",
    "            \n",
    "        \n",
    "    # ラベルの生成\n",
    "    for t in train_or_test:\n",
    "        if t == \"train\":\n",
    "            for i in range(num_classes):\n",
    "                if i == 0:\n",
    "                    label = np.full(y_train[i] , i )    \n",
    "                else:\n",
    "                    label_ = np.full(y_train[i] , i )   \n",
    "                    label = np.append(label, label_, axis=0)\n",
    "            y_train = label\n",
    "\n",
    "        if t == \"test\":\n",
    "            for i in range(num_classes):\n",
    "                if i == 0:\n",
    "                    label = np.full(y_test[i] , i )    \n",
    "                else:\n",
    "                    label_ = np.full(y_test[i] , i )   \n",
    "                    label = np.append(label, label_, axis=0)\n",
    "            y_test = label\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    # 保存\n",
    "    npy = [\"x_train.npy\" , \"x_test.npy\" , \"y_train.npy\" , \"y_test.npy\"]\n",
    "    data = [x_train , x_test , y_train , y_test]\n",
    "    for i in range(len(npy)):\n",
    "        np.save(dist_dir + npy[i],data[i])\n",
    "        \n",
    "    # 不要ファイルの除去\n",
    "#     for i in os.listdir(dist_dir):\n",
    "#         if not i in npy:\n",
    "#             os.remove(dist_dir + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
